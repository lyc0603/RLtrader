{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "4L9MAoJXCCdB"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import itertools\n",
        "import argparse\n",
        "import re\n",
        "import os\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch as T\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import jupyter_black\n",
        "\n",
        "jupyter_black.load()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load crypto data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_data():\n",
        "    \"\"\"\n",
        "    Get the data from the csv file\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_csv(\"crypto.csv\")\n",
        "\n",
        "    # only keep the columns we need\n",
        "    df = df[[\"Symbol\", \"Date\", \"Close\"]]\n",
        "\n",
        "    # show all cryptocurrencies\n",
        "    df[\"Symbol\"].unique()\n",
        "\n",
        "    # only keep BTC, ETH, BNB\n",
        "    df = df[df[\"Symbol\"].isin([\"BTC\", \"ETH\", \"BNB\", \"XRP\", \"Dogecoin\"])]\n",
        "\n",
        "    # check is there any missing data\n",
        "    df.isnull().sum()\n",
        "\n",
        "    # convert Date column to datetime\n",
        "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "\n",
        "    # sort by date\n",
        "    df = df.sort_values(\"Date\")\n",
        "\n",
        "    # groupby Symbol and check the number of days\n",
        "    df.groupby(\"Symbol\")[\"Date\"].describe(datetime_is_numeric=True)\n",
        "\n",
        "    # only keep the data from 2018-01-01 to 2021-06-01\n",
        "    df = df[(df[\"Date\"] >= \"2018-01-01\") & (df[\"Date\"] <= \"2021-06-01\")]\n",
        "\n",
        "    # each row is a cryptocurrency\n",
        "    df = df.pivot(index=\"Date\", columns=\"Symbol\", values=\"Close\")\n",
        "\n",
        "    return df.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "5VpQ5TULFGFa"
      },
      "outputs": [],
      "source": [
        "def get_scaler(env):\n",
        "    # return scikit-learn scaler object to scale the states\n",
        "    # Note: you could also populate the replay buffer here\n",
        "\n",
        "    states = []\n",
        "    for _ in range(env.n_step):\n",
        "        action = np.random.choice(env.action_space)\n",
        "        state, reward, done, info = env.step(action)\n",
        "        states.append(state)\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(states)\n",
        "    return scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "9xHiB1R4FMnu"
      },
      "outputs": [],
      "source": [
        "def maybe_make_dir(directory):\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DQN(nn.Module):\n",
        "    \"\"\"\n",
        "    Agent for DQN\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, input_dim, n_action, lr=0.01, fc1_dims=8, fc2_dims=8,):\n",
        "\n",
        "        # initialize the parent class\n",
        "        super(DQN, self).__init__()\n",
        "        self.input_dims = input_dim\n",
        "        self.fc1_dims = fc1_dims\n",
        "        self.fc2_dims = fc2_dims\n",
        "        self.n_actions = n_action\n",
        "        \n",
        "        self.fc1 = nn.Linear(*self.input_dims, self.fc1_dims)\n",
        "        self.fc2 = nn.Linear(self.fc1_dims, self.fc2_dims)\n",
        "        self.fc3 = nn.Linear(self.fc2_dims, self.n_actions)\n",
        "        \n",
        "        # weight initialization\n",
        "        nn.init.xavier_uniform_(self.fc1.weight)\n",
        "        nn.init.xavier_uniform_(self.fc2.weight)\n",
        "        nn.init.xavier_uniform_(self.fc3.weight)\n",
        "\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=lr)\n",
        "        self.loss = nn.MSELoss()\n",
        "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, state):\n",
        "        \"\"\"\n",
        "        Forward pass\n",
        "        \"\"\"\n",
        "        x = F.relu(self.fc1(state))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        actions = self.fc3(x)\n",
        "        return actions\n",
        "    \n",
        "    def predict(self, state):\n",
        "        \"\"\"\n",
        "        Predict the action\n",
        "        \"\"\"\n",
        "        state = T.tensor(state, dtype=T.float).to(self.device)\n",
        "        actions = self.forward(state)\n",
        "        return actions\n",
        "\n",
        "    def save_weights(self, path):\n",
        "        T.save(self.state_dict(), path)\n",
        "\n",
        "    def load_weights(self, path):\n",
        "        self.load_state_dict(T.load(path))\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "yQpsgYF-FOsj"
      },
      "outputs": [],
      "source": [
        "# class LinearModel:\n",
        "#     \"\"\"A linear regression model\"\"\"\n",
        "\n",
        "#     def __init__(self, input_dim, n_action):\n",
        "#         self.W = np.random.randn(input_dim, n_action) / np.sqrt(input_dim)\n",
        "#         self.b = np.zeros(n_action)\n",
        "\n",
        "#         # momentum terms\n",
        "#         self.vW = 0\n",
        "#         self.vb = 0\n",
        "\n",
        "#         self.losses = []\n",
        "\n",
        "#     def predict(self, X):\n",
        "#         # make sure X is N x D (N sample size - how many obs we use, D state dimension - 7 in our case)\n",
        "#         assert (\n",
        "#             len(X.shape) == 2\n",
        "#         )  # assert is to chech if the condition is TRUE otherwise we have a warning error!\n",
        "#         return X.dot(self.W) + self.b\n",
        "\n",
        "#     def sgd(self, X, Y, learning_rate=0.01, momentum=0.9):\n",
        "#         # make sure X is N x D\n",
        "#         assert len(X.shape) == 2\n",
        "\n",
        "#         # X is the current Q(s,:)\n",
        "#         # Y is the target r + gamma max Q(s',:)\n",
        "#         # the loss values are 2-D\n",
        "#         # normally we would divide by N only\n",
        "#         # but now we divide by N x K - K is num_action, i.e. the number of outputs\n",
        "#         num_values = np.prod(Y.shape)\n",
        "\n",
        "#         # do one step of gradient descent\n",
        "#         # we multiply by 2 to get the exact gradient\n",
        "#         # (not adjusting the learning rate)\n",
        "#         # i.e. d/dx (x^2) --> 2x\n",
        "#         Yhat = self.predict(X)\n",
        "#         gW = (\n",
        "#             2 * X.T.dot(Yhat - Y) / num_values\n",
        "#         )  # here 2 is because of the derivative of the mean squared error \\sum_{k=1}^n_action (y-yhat)^2\n",
        "#         gb = 2 * (Yhat - Y).sum(axis=0) / num_values\n",
        "\n",
        "#         # update momentum terms\n",
        "#         self.vW = momentum * self.vW - learning_rate * gW\n",
        "#         self.vb = momentum * self.vb - learning_rate * gb\n",
        "\n",
        "#         # update params\n",
        "#         self.W += self.vW\n",
        "#         self.b += self.vb\n",
        "\n",
        "#         mse = np.mean((Yhat - Y) ** 2)\n",
        "#         self.losses.append(mse)\n",
        "\n",
        "#     def load_weights(self, filepath):\n",
        "#         npz = np.load(filepath)\n",
        "#         self.W = npz[\"W\"]\n",
        "#         self.b = npz[\"b\"]\n",
        "\n",
        "#     def save_weights(self, filepath):\n",
        "#         np.savez(filepath, W=self.W, b=self.b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "_ysfQDTcFgq0"
      },
      "outputs": [],
      "source": [
        "class MultiStockEnv:\n",
        "    \"\"\"\n",
        "    A 3-crypto trading environment.\n",
        "    State: vector of size 7 (n_stock * 2 + 1)\n",
        "      - # shares of stock 1 owned\n",
        "      - # shares of stock 2 owned\n",
        "      - # shares of stock 3 owned\n",
        "      - price of stock 1 (using daily close price)\n",
        "      - price of stock 2\n",
        "      - price of stock 3\n",
        "      - cash owned (can be used to purchase more stocks)\n",
        "    Action: categorical variable with 27 (3^3) possibilities\n",
        "      - for each stock, you can:\n",
        "      - 0 = sell\n",
        "      - 1 = hold\n",
        "      - 2 = buy\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data, initial_investment=20000):\n",
        "        # data\n",
        "        self.stock_price_history = data\n",
        "        self.n_step, self.n_stock = self.stock_price_history.shape\n",
        "\n",
        "        # instance attributes\n",
        "        self.initial_investment = initial_investment\n",
        "        self.cur_step = None\n",
        "        self.stock_owned = None\n",
        "        self.stock_price = None\n",
        "        self.cash_in_hand = None\n",
        "\n",
        "        self.action_space = np.arange(3**self.n_stock)\n",
        "\n",
        "        # action permutations\n",
        "        # returns a nested list with elements like:\n",
        "        # [0,0,0]\n",
        "        # [0,0,1]\n",
        "        # [0,0,2]\n",
        "        # [0,1,0]\n",
        "        # [0,1,1]\n",
        "        # etc.\n",
        "        # 0 = sell\n",
        "        # 1 = hold\n",
        "        # 2 = buy\n",
        "        self.action_list = list(\n",
        "            map(list, itertools.product([0, 1, 2], repeat=self.n_stock))\n",
        "        )\n",
        "\n",
        "        # calculate size of state\n",
        "        self.state_dim = self.n_stock * 2 + 1\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.cur_step = 0\n",
        "        self.stock_owned = np.zeros(self.n_stock)\n",
        "        self.stock_price = self.stock_price_history[self.cur_step]\n",
        "        self.cash_in_hand = self.initial_investment\n",
        "        return self._get_obs()\n",
        "\n",
        "    def step(self, action):\n",
        "        assert action in self.action_space\n",
        "\n",
        "        # get current value before performing the action\n",
        "        prev_val = self._get_val()\n",
        "\n",
        "        # update price, i.e. go to the next day\n",
        "        self.cur_step += 1\n",
        "        self.stock_price = self.stock_price_history[self.cur_step]\n",
        "\n",
        "        # perform the trade\n",
        "        self._trade(action)\n",
        "\n",
        "        # get the new value after taking the action\n",
        "        cur_val = self._get_val()\n",
        "\n",
        "        # reward is the increase in porfolio value\n",
        "        reward = cur_val - prev_val\n",
        "\n",
        "        # done if we have run out of data\n",
        "        done = self.cur_step == self.n_step - 1\n",
        "\n",
        "        # store the current value of the portfolio here\n",
        "        info = {\"cur_val\": cur_val}\n",
        "\n",
        "        # conform to the Gym API\n",
        "        return self._get_obs(), reward, done, info\n",
        "\n",
        "    def _get_obs(self):\n",
        "        obs = np.empty(self.state_dim)\n",
        "        obs[: self.n_stock] = self.stock_owned\n",
        "        obs[self.n_stock : 2 * self.n_stock] = self.stock_price\n",
        "        obs[-1] = self.cash_in_hand\n",
        "        return obs\n",
        "\n",
        "    def _get_val(self):\n",
        "        return self.stock_owned.dot(self.stock_price) + self.cash_in_hand\n",
        "\n",
        "    def _trade(self, action):\n",
        "        # index the action we want to perform\n",
        "        # 0 = sell\n",
        "        # 1 = hold\n",
        "        # 2 = buy\n",
        "        # e.g. [2,1,0] means:\n",
        "        # buy first stock\n",
        "        # hold second stock\n",
        "        # sell third stock\n",
        "        action_vec = self.action_list[action]\n",
        "\n",
        "        # determine which stocks to buy or sell\n",
        "        sell_index = []  # stores index of stocks we want to sell\n",
        "        buy_index = []  # stores index of stocks we want to buy\n",
        "        for i, a in enumerate(action_vec):\n",
        "            if a == 0:\n",
        "                sell_index.append(i)\n",
        "            elif a == 2:\n",
        "                buy_index.append(i)\n",
        "\n",
        "        # sell any stocks we want to sell\n",
        "        # then buy any stocks we want to buy\n",
        "        if sell_index:\n",
        "            # NOTE: to simplify the problem, when we sell, we will sell ALL shares of that stock\n",
        "            for i in sell_index:\n",
        "                self.cash_in_hand += self.stock_price[i] * self.stock_owned[i]\n",
        "                self.stock_owned[i] = 0\n",
        "        if buy_index:\n",
        "            # NOTE: when buying, we will loop through each stock we want to buy,\n",
        "            #       and buy one share at a time until we run out of cash\n",
        "            can_buy = True\n",
        "            while can_buy:\n",
        "                for i in buy_index:\n",
        "                    if self.cash_in_hand > self.stock_price[i]:\n",
        "                        self.stock_owned[i] += 1  # buy one share\n",
        "                        self.cash_in_hand -= self.stock_price[i]\n",
        "                    else:\n",
        "                        can_buy = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "DEiFa9k6Fl2e"
      },
      "outputs": [],
      "source": [
        "class DQNAgent(object):\n",
        "    def __init__(self, state_size, action_size):\n",
        "        self.state_size = state_size  # D\n",
        "        self.action_size = action_size  # num_action or K before\n",
        "        self.gamma = 0.95  # discount rate\n",
        "        self.epsilon = 1.0  # exploration rate\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = 0.995\n",
        "        self.model = DQN(state_size, action_size)\n",
        "\n",
        "    def act(self, state):  # epsilon-greedy strategy\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return np.random.choice(self.action_size)\n",
        "        act_values = self.model.predict(state)\n",
        "        return np.argmax(\n",
        "            act_values[0]\n",
        "        )  # returns action - 0 because here we have just N = 1 observation\n",
        "\n",
        "    def train(self, state, action, reward, next_state, done):\n",
        "        if done:\n",
        "            target = reward  # terminal state\n",
        "        else:\n",
        "            target = reward + self.gamma * np.amax(\n",
        "                self.model.predict(next_state), axis=1\n",
        "            )  # any other state, this is r + \\gamma Q(s',a')\n",
        "\n",
        "        target_full = self.model.predict(state)  # this is Q(s,:)\n",
        "        target_full[0, action] = target  # here we consider only Q(s,a)\n",
        "\n",
        "        # Run one training step\n",
        "        self.model.sgd(\n",
        "            state, target_full\n",
        "        )  # gradient descent method: we update only Q(s,a) -> for action a\n",
        "\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= (\n",
        "                self.epsilon_decay\n",
        "            )  # update of the \\epsilon for learning -> decreasing in time\n",
        "\n",
        "    def load(self, name):\n",
        "        self.model.load_weights(name)  # we load W and b\n",
        "\n",
        "    def save(self, name):\n",
        "        self.model.save_weights(\n",
        "            name\n",
        "        )  # we save the new W and b - it is useful if we want to test some particula W and b at specific time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "VGnwde0hFqXZ"
      },
      "outputs": [],
      "source": [
        "def play_one_episode(agent, env, is_train):\n",
        "    # note: after transforming states are already 1xD\n",
        "    # env is used to call the class \"MultiStockEnv\"\n",
        "    state = env.reset()\n",
        "    state = scaler.transform([state])\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        action = agent.act(state)\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "        next_state = scaler.transform([next_state])\n",
        "        if is_train == \"train\":\n",
        "            agent.train(state, action, reward, next_state, done)\n",
        "        state = next_state\n",
        "\n",
        "    return info[\"cur_val\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "pCMAs7ifLfeM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "episode: 1/2000, episode end value: 14682.79, duration: 0:00:00.205499\n",
            "episode: 2/2000, episode end value: 57734.65, duration: 0:00:00.061401\n",
            "episode: 3/2000, episode end value: 82706.63, duration: 0:00:00.062978\n",
            "episode: 4/2000, episode end value: 59072.58, duration: 0:00:00.125182\n",
            "episode: 5/2000, episode end value: 28910.07, duration: 0:00:00.142396\n",
            "episode: 6/2000, episode end value: 92283.93, duration: 0:00:00.171002\n",
            "episode: 7/2000, episode end value: 103848.93, duration: 0:00:00.091618\n",
            "episode: 8/2000, episode end value: 40254.50, duration: 0:00:00.063010\n",
            "episode: 9/2000, episode end value: 20702.99, duration: 0:00:00.085749\n",
            "episode: 10/2000, episode end value: 57079.56, duration: 0:00:00.261697\n",
            "episode: 11/2000, episode end value: 121740.61, duration: 0:00:00.170886\n",
            "episode: 12/2000, episode end value: 124294.93, duration: 0:00:00.248131\n",
            "episode: 13/2000, episode end value: 83778.61, duration: 0:00:00.441101\n",
            "episode: 14/2000, episode end value: 33197.17, duration: 0:00:01.709869\n",
            "episode: 15/2000, episode end value: 22670.49, duration: 0:00:01.941996\n",
            "episode: 16/2000, episode end value: 45720.07, duration: 0:00:04.992468\n",
            "episode: 17/2000, episode end value: 59297.83, duration: 0:00:04.848870\n",
            "episode: 18/2000, episode end value: 11005.88, duration: 0:00:00.280607\n",
            "episode: 19/2000, episode end value: 71422.05, duration: 0:00:05.016467\n",
            "episode: 20/2000, episode end value: 41552.50, duration: 0:00:02.406656\n",
            "episode: 21/2000, episode end value: 76515.22, duration: 0:00:02.515258\n",
            "episode: 22/2000, episode end value: 18612.05, duration: 0:00:00.578634\n",
            "episode: 23/2000, episode end value: 8897.38, duration: 0:00:00.511148\n",
            "episode: 24/2000, episode end value: 113585.88, duration: 0:00:01.211175\n",
            "episode: 25/2000, episode end value: 41995.28, duration: 0:00:00.447149\n",
            "episode: 26/2000, episode end value: 100601.63, duration: 0:00:00.968370\n",
            "episode: 27/2000, episode end value: 124836.82, duration: 0:00:00.427537\n",
            "episode: 28/2000, episode end value: 79086.01, duration: 0:00:00.742861\n",
            "episode: 29/2000, episode end value: 70551.15, duration: 0:00:00.169287\n",
            "episode: 30/2000, episode end value: 92900.60, duration: 0:00:00.102697\n",
            "episode: 31/2000, episode end value: 78420.60, duration: 0:00:00.115002\n",
            "episode: 32/2000, episode end value: 128175.77, duration: 0:00:00.808804\n",
            "episode: 33/2000, episode end value: 32214.80, duration: 0:00:00.056077\n",
            "episode: 34/2000, episode end value: 71148.76, duration: 0:00:00.101090\n",
            "episode: 35/2000, episode end value: 51456.70, duration: 0:00:00.298934\n",
            "episode: 36/2000, episode end value: 59486.93, duration: 0:00:01.259640\n",
            "episode: 37/2000, episode end value: 91048.22, duration: 0:00:00.928192\n",
            "episode: 38/2000, episode end value: 65793.42, duration: 0:00:04.240866\n",
            "episode: 39/2000, episode end value: 28470.32, duration: 0:00:03.366946\n",
            "episode: 40/2000, episode end value: 41700.25, duration: 0:00:06.427435\n",
            "episode: 41/2000, episode end value: 23610.43, duration: 0:00:02.972556\n",
            "episode: 42/2000, episode end value: 31712.21, duration: 0:00:01.087111\n",
            "episode: 43/2000, episode end value: 35373.10, duration: 0:00:01.260042\n",
            "episode: 44/2000, episode end value: 99259.79, duration: 0:00:08.051421\n",
            "episode: 45/2000, episode end value: 6530.63, duration: 0:00:00.351932\n",
            "episode: 46/2000, episode end value: 47377.10, duration: 0:00:03.630200\n",
            "episode: 47/2000, episode end value: 311738.95, duration: 0:00:03.217698\n",
            "episode: 48/2000, episode end value: 13855.00, duration: 0:00:00.086298\n",
            "episode: 49/2000, episode end value: 10860.08, duration: 0:00:00.048732\n",
            "episode: 50/2000, episode end value: 9941.22, duration: 0:00:00.084060\n",
            "episode: 51/2000, episode end value: 12783.55, duration: 0:00:00.072163\n",
            "episode: 52/2000, episode end value: 16199.37, duration: 0:00:00.526437\n",
            "episode: 53/2000, episode end value: 50235.75, duration: 0:00:00.718923\n",
            "episode: 54/2000, episode end value: 43874.34, duration: 0:00:02.286094\n",
            "episode: 55/2000, episode end value: 28347.07, duration: 0:00:00.164311\n",
            "episode: 56/2000, episode end value: 35101.16, duration: 0:00:00.142718\n",
            "episode: 57/2000, episode end value: 126442.39, duration: 0:00:00.344812\n",
            "episode: 58/2000, episode end value: 44800.83, duration: 0:00:02.940208\n",
            "episode: 59/2000, episode end value: 25269.39, duration: 0:00:00.269844\n",
            "episode: 60/2000, episode end value: 24883.03, duration: 0:00:00.339719\n",
            "episode: 61/2000, episode end value: 47163.08, duration: 0:00:00.158109\n",
            "episode: 62/2000, episode end value: 24115.40, duration: 0:00:00.148376\n",
            "episode: 63/2000, episode end value: 42467.70, duration: 0:00:00.500431\n",
            "episode: 64/2000, episode end value: 44984.94, duration: 0:00:00.715429\n",
            "episode: 65/2000, episode end value: 32210.56, duration: 0:00:00.239503\n",
            "episode: 66/2000, episode end value: 180140.45, duration: 0:00:05.266937\n",
            "episode: 67/2000, episode end value: 32955.66, duration: 0:00:03.219412\n",
            "episode: 68/2000, episode end value: 10069.22, duration: 0:00:00.166446\n",
            "episode: 69/2000, episode end value: 8977.76, duration: 0:00:00.736489\n",
            "episode: 70/2000, episode end value: 7427.26, duration: 0:00:02.540871\n",
            "episode: 71/2000, episode end value: 8411.72, duration: 0:00:04.544268\n",
            "episode: 72/2000, episode end value: 10246.13, duration: 0:00:05.564485\n",
            "episode: 73/2000, episode end value: 21790.41, duration: 0:00:07.321363\n",
            "episode: 74/2000, episode end value: 5738.64, duration: 0:00:02.157589\n",
            "episode: 75/2000, episode end value: 35902.79, duration: 0:00:07.548004\n",
            "episode: 76/2000, episode end value: 101396.12, duration: 0:00:12.997934\n",
            "episode: 77/2000, episode end value: 24854.30, duration: 0:00:05.982535\n",
            "episode: 78/2000, episode end value: 33520.37, duration: 0:00:05.732214\n",
            "episode: 79/2000, episode end value: 10390.23, duration: 0:00:05.047517\n",
            "episode: 80/2000, episode end value: 10203.51, duration: 0:00:02.334870\n",
            "episode: 81/2000, episode end value: 12308.42, duration: 0:00:03.187084\n",
            "episode: 82/2000, episode end value: 15818.86, duration: 0:00:04.577741\n",
            "episode: 83/2000, episode end value: 8241.00, duration: 0:00:02.697071\n",
            "episode: 84/2000, episode end value: 32439.79, duration: 0:00:06.179426\n",
            "episode: 85/2000, episode end value: 63320.29, duration: 0:00:07.204829\n",
            "episode: 86/2000, episode end value: 32847.20, duration: 0:00:06.629099\n",
            "episode: 87/2000, episode end value: 33471.11, duration: 0:00:05.532095\n",
            "episode: 88/2000, episode end value: 39537.51, duration: 0:00:06.337789\n",
            "episode: 89/2000, episode end value: 118578.53, duration: 0:00:02.737250\n",
            "episode: 90/2000, episode end value: 22001.99, duration: 0:00:04.532592\n",
            "episode: 91/2000, episode end value: 29468.57, duration: 0:00:06.194879\n",
            "episode: 92/2000, episode end value: 56975.44, duration: 0:00:07.066607\n",
            "episode: 93/2000, episode end value: 14228.56, duration: 0:00:03.068257\n",
            "episode: 94/2000, episode end value: 76928.87, duration: 0:00:03.610354\n",
            "episode: 95/2000, episode end value: 441946.55, duration: 0:00:02.388904\n",
            "episode: 96/2000, episode end value: 21328.29, duration: 0:00:00.144265\n",
            "episode: 97/2000, episode end value: 9929.65, duration: 0:00:00.101739\n",
            "episode: 98/2000, episode end value: 9072.81, duration: 0:00:00.369036\n",
            "episode: 99/2000, episode end value: 34289.92, duration: 0:00:03.217643\n",
            "episode: 100/2000, episode end value: 10527.94, duration: 0:00:00.372136\n",
            "episode: 101/2000, episode end value: 105629.06, duration: 0:00:02.236336\n",
            "episode: 102/2000, episode end value: 41776.90, duration: 0:00:06.519598\n",
            "episode: 103/2000, episode end value: 13641.80, duration: 0:00:00.183991\n",
            "episode: 104/2000, episode end value: 10781.26, duration: 0:00:00.100867\n",
            "episode: 105/2000, episode end value: 60225.22, duration: 0:00:05.550573\n",
            "episode: 106/2000, episode end value: 59489.20, duration: 0:00:04.737013\n",
            "episode: 107/2000, episode end value: 50931.51, duration: 0:00:04.835780\n",
            "episode: 108/2000, episode end value: 179268.31, duration: 0:00:00.154201\n",
            "episode: 109/2000, episode end value: 42672.66, duration: 0:00:04.622864\n",
            "episode: 110/2000, episode end value: 86354.22, duration: 0:00:00.292205\n",
            "episode: 111/2000, episode end value: 26004.47, duration: 0:00:03.516531\n",
            "episode: 112/2000, episode end value: 43807.73, duration: 0:00:05.033902\n",
            "episode: 113/2000, episode end value: 47789.69, duration: 0:00:03.283895\n",
            "episode: 114/2000, episode end value: 88876.54, duration: 0:00:04.375273\n",
            "episode: 115/2000, episode end value: 49040.13, duration: 0:00:01.784869\n",
            "episode: 116/2000, episode end value: 48361.28, duration: 0:00:01.765234\n",
            "episode: 117/2000, episode end value: 14624.90, duration: 0:00:00.162686\n",
            "episode: 118/2000, episode end value: 54878.23, duration: 0:00:00.601902\n",
            "episode: 119/2000, episode end value: 38679.54, duration: 0:00:03.127370\n",
            "episode: 120/2000, episode end value: 76937.65, duration: 0:00:07.247698\n",
            "episode: 121/2000, episode end value: 97705.24, duration: 0:00:00.146066\n",
            "episode: 122/2000, episode end value: 68205.61, duration: 0:00:00.179483\n",
            "episode: 123/2000, episode end value: 35677.92, duration: 0:00:01.603870\n",
            "episode: 124/2000, episode end value: 41645.64, duration: 0:00:02.195066\n",
            "episode: 125/2000, episode end value: 50815.59, duration: 0:00:02.129307\n",
            "episode: 126/2000, episode end value: 66817.41, duration: 0:00:01.753121\n",
            "episode: 127/2000, episode end value: 93036.26, duration: 0:00:02.050538\n",
            "episode: 128/2000, episode end value: 98673.93, duration: 0:00:01.267513\n",
            "episode: 129/2000, episode end value: 59335.66, duration: 0:00:04.583056\n",
            "episode: 130/2000, episode end value: 102638.65, duration: 0:00:00.278816\n",
            "episode: 131/2000, episode end value: 6801.69, duration: 0:00:00.190013\n",
            "episode: 132/2000, episode end value: 179165.78, duration: 0:00:04.052151\n",
            "episode: 133/2000, episode end value: 125340.37, duration: 0:00:00.623798\n",
            "episode: 134/2000, episode end value: 93029.93, duration: 0:00:00.105358\n",
            "episode: 135/2000, episode end value: 54243.08, duration: 0:00:00.463915\n",
            "episode: 136/2000, episode end value: 64206.92, duration: 0:00:00.263058\n",
            "episode: 137/2000, episode end value: 65531.14, duration: 0:00:00.741260\n",
            "episode: 138/2000, episode end value: 67463.07, duration: 0:00:02.483401\n",
            "episode: 139/2000, episode end value: 35548.72, duration: 0:00:02.296356\n",
            "episode: 140/2000, episode end value: 43084.74, duration: 0:00:00.151612\n",
            "episode: 141/2000, episode end value: 53816.26, duration: 0:00:00.143076\n",
            "episode: 142/2000, episode end value: 108460.33, duration: 0:00:00.116152\n",
            "episode: 143/2000, episode end value: 66785.50, duration: 0:00:00.302177\n",
            "episode: 144/2000, episode end value: 81571.92, duration: 0:00:00.342182\n",
            "episode: 145/2000, episode end value: 70416.53, duration: 0:00:00.229655\n",
            "episode: 146/2000, episode end value: 71474.34, duration: 0:00:00.281326\n",
            "episode: 147/2000, episode end value: 39261.46, duration: 0:00:00.470391\n",
            "episode: 148/2000, episode end value: 78089.85, duration: 0:00:00.783069\n",
            "episode: 149/2000, episode end value: 136787.07, duration: 0:00:02.376202\n",
            "episode: 150/2000, episode end value: 142657.63, duration: 0:00:00.138543\n",
            "episode: 151/2000, episode end value: 122160.44, duration: 0:00:00.064533\n",
            "episode: 152/2000, episode end value: 249850.79, duration: 0:00:06.461360\n",
            "episode: 153/2000, episode end value: 91442.16, duration: 0:00:00.072576\n",
            "episode: 154/2000, episode end value: 105776.81, duration: 0:00:00.053021\n",
            "episode: 155/2000, episode end value: 78549.12, duration: 0:00:00.135322\n",
            "episode: 156/2000, episode end value: 75433.20, duration: 0:00:00.127692\n",
            "episode: 157/2000, episode end value: 114724.85, duration: 0:00:00.181158\n",
            "episode: 158/2000, episode end value: 69621.47, duration: 0:00:00.508613\n",
            "episode: 159/2000, episode end value: 212097.89, duration: 0:00:01.318513\n",
            "episode: 160/2000, episode end value: 96983.61, duration: 0:00:00.493674\n",
            "episode: 161/2000, episode end value: 47381.16, duration: 0:00:02.638546\n",
            "episode: 162/2000, episode end value: 96196.92, duration: 0:00:00.998799\n",
            "episode: 163/2000, episode end value: 66542.24, duration: 0:00:00.205385\n",
            "episode: 164/2000, episode end value: 82597.07, duration: 0:00:00.237282\n",
            "episode: 165/2000, episode end value: 153091.68, duration: 0:00:03.286691\n",
            "episode: 166/2000, episode end value: 225113.99, duration: 0:00:04.845278\n",
            "episode: 167/2000, episode end value: 81673.83, duration: 0:00:00.916763\n",
            "episode: 168/2000, episode end value: 71820.26, duration: 0:00:00.602007\n",
            "episode: 169/2000, episode end value: 159970.64, duration: 0:00:03.215356\n",
            "episode: 170/2000, episode end value: 38653.89, duration: 0:00:01.660452\n",
            "episode: 171/2000, episode end value: 37585.22, duration: 0:00:01.421933\n",
            "episode: 172/2000, episode end value: 72061.81, duration: 0:00:00.652993\n",
            "episode: 173/2000, episode end value: 52445.35, duration: 0:00:00.286750\n",
            "episode: 174/2000, episode end value: 96103.24, duration: 0:00:00.763850\n",
            "episode: 175/2000, episode end value: 59481.02, duration: 0:00:01.547833\n",
            "episode: 176/2000, episode end value: 115770.06, duration: 0:00:04.656725\n",
            "episode: 177/2000, episode end value: 87249.80, duration: 0:00:00.394966\n",
            "episode: 178/2000, episode end value: 104487.25, duration: 0:00:00.100487\n",
            "episode: 179/2000, episode end value: 127941.49, duration: 0:00:00.158534\n",
            "episode: 180/2000, episode end value: 88254.53, duration: 0:00:02.277379\n",
            "episode: 181/2000, episode end value: 63269.96, duration: 0:00:02.229719\n",
            "episode: 182/2000, episode end value: 68637.38, duration: 0:00:07.503538\n",
            "episode: 183/2000, episode end value: 185123.67, duration: 0:00:01.460339\n",
            "episode: 184/2000, episode end value: 69313.12, duration: 0:00:06.953051\n",
            "episode: 185/2000, episode end value: 123139.25, duration: 0:00:05.157805\n",
            "episode: 186/2000, episode end value: 94198.64, duration: 0:00:02.394063\n",
            "episode: 187/2000, episode end value: 92615.96, duration: 0:00:02.145562\n",
            "episode: 188/2000, episode end value: 77323.61, duration: 0:00:00.296081\n",
            "episode: 189/2000, episode end value: 91155.64, duration: 0:00:04.817680\n",
            "episode: 190/2000, episode end value: 69879.32, duration: 0:00:03.519938\n",
            "episode: 191/2000, episode end value: 93990.95, duration: 0:00:02.484648\n",
            "episode: 192/2000, episode end value: 77396.68, duration: 0:00:00.064520\n",
            "episode: 193/2000, episode end value: 92896.75, duration: 0:00:01.363028\n",
            "episode: 194/2000, episode end value: 108449.16, duration: 0:00:00.332043\n",
            "episode: 195/2000, episode end value: 122448.36, duration: 0:00:00.171890\n",
            "episode: 196/2000, episode end value: 84595.64, duration: 0:00:00.189753\n",
            "episode: 197/2000, episode end value: 71389.63, duration: 0:00:01.859678\n",
            "episode: 198/2000, episode end value: 113830.16, duration: 0:00:00.121797\n",
            "episode: 199/2000, episode end value: 116323.68, duration: 0:00:00.182414\n",
            "episode: 200/2000, episode end value: 141687.30, duration: 0:00:00.080044\n",
            "episode: 201/2000, episode end value: 17294.71, duration: 0:00:01.557662\n",
            "episode: 202/2000, episode end value: 97515.31, duration: 0:00:00.094360\n",
            "episode: 203/2000, episode end value: 317944.40, duration: 0:00:00.087033\n",
            "episode: 204/2000, episode end value: 105275.74, duration: 0:00:00.064889\n",
            "episode: 205/2000, episode end value: 145539.77, duration: 0:00:00.095634\n",
            "episode: 206/2000, episode end value: 54477.65, duration: 0:00:00.209145\n",
            "episode: 207/2000, episode end value: 64664.88, duration: 0:00:00.124244\n",
            "episode: 208/2000, episode end value: 134695.89, duration: 0:00:00.072896\n",
            "episode: 209/2000, episode end value: 57091.95, duration: 0:00:02.999691\n",
            "episode: 210/2000, episode end value: 125688.41, duration: 0:00:02.658976\n",
            "episode: 211/2000, episode end value: 86638.78, duration: 0:00:00.883923\n",
            "episode: 212/2000, episode end value: 35497.75, duration: 0:00:00.416472\n",
            "episode: 213/2000, episode end value: 44279.35, duration: 0:00:00.359174\n",
            "episode: 214/2000, episode end value: 45660.66, duration: 0:00:01.006434\n",
            "episode: 215/2000, episode end value: 45714.88, duration: 0:00:02.762181\n",
            "episode: 216/2000, episode end value: 44821.70, duration: 0:00:02.617375\n",
            "episode: 217/2000, episode end value: 87882.66, duration: 0:00:00.377805\n",
            "episode: 218/2000, episode end value: 83824.55, duration: 0:00:00.567594\n",
            "episode: 219/2000, episode end value: 70176.95, duration: 0:00:02.162116\n",
            "episode: 220/2000, episode end value: 45728.63, duration: 0:00:00.759105\n",
            "episode: 221/2000, episode end value: 28892.74, duration: 0:00:00.666831\n",
            "episode: 222/2000, episode end value: 54133.09, duration: 0:00:00.072120\n",
            "episode: 223/2000, episode end value: 33084.23, duration: 0:00:00.512312\n",
            "episode: 224/2000, episode end value: 94207.13, duration: 0:00:00.160023\n",
            "episode: 225/2000, episode end value: 94752.98, duration: 0:00:00.079211\n",
            "episode: 226/2000, episode end value: 104922.00, duration: 0:00:00.538455\n",
            "episode: 227/2000, episode end value: 127007.88, duration: 0:00:00.162076\n",
            "episode: 228/2000, episode end value: 59259.25, duration: 0:00:03.341243\n",
            "episode: 229/2000, episode end value: 138431.14, duration: 0:00:01.453443\n",
            "episode: 230/2000, episode end value: 79440.83, duration: 0:00:03.937167\n",
            "episode: 231/2000, episode end value: 51879.35, duration: 0:00:00.234349\n",
            "episode: 232/2000, episode end value: 103582.26, duration: 0:00:00.627534\n",
            "episode: 233/2000, episode end value: 126346.73, duration: 0:00:00.298355\n",
            "episode: 234/2000, episode end value: 180489.48, duration: 0:00:00.463369\n",
            "episode: 235/2000, episode end value: 130869.28, duration: 0:00:00.436715\n",
            "episode: 236/2000, episode end value: 60003.28, duration: 0:00:01.633470\n",
            "episode: 237/2000, episode end value: 89169.21, duration: 0:00:00.164139\n",
            "episode: 238/2000, episode end value: 121062.95, duration: 0:00:01.363935\n",
            "episode: 239/2000, episode end value: 216858.62, duration: 0:00:05.258984\n",
            "episode: 240/2000, episode end value: 98665.74, duration: 0:00:00.303837\n",
            "episode: 241/2000, episode end value: 194692.32, duration: 0:00:01.072006\n",
            "episode: 242/2000, episode end value: 126286.89, duration: 0:00:05.523466\n",
            "episode: 243/2000, episode end value: 116691.57, duration: 0:00:03.986320\n",
            "episode: 244/2000, episode end value: 104494.22, duration: 0:00:00.112259\n",
            "episode: 245/2000, episode end value: 71976.51, duration: 0:00:00.192741\n",
            "episode: 246/2000, episode end value: 89891.60, duration: 0:00:00.255840\n",
            "episode: 247/2000, episode end value: 126728.22, duration: 0:00:00.267916\n",
            "episode: 248/2000, episode end value: 72551.93, duration: 0:00:00.279030\n",
            "episode: 249/2000, episode end value: 131578.36, duration: 0:00:00.203787\n",
            "episode: 250/2000, episode end value: 82928.96, duration: 0:00:00.319902\n",
            "episode: 251/2000, episode end value: 31032.65, duration: 0:00:01.398251\n",
            "episode: 252/2000, episode end value: 87306.22, duration: 0:00:00.389166\n",
            "episode: 253/2000, episode end value: 68623.88, duration: 0:00:00.687301\n",
            "episode: 254/2000, episode end value: 111591.41, duration: 0:00:00.264827\n",
            "episode: 255/2000, episode end value: 138792.13, duration: 0:00:00.207532\n",
            "episode: 256/2000, episode end value: 96471.68, duration: 0:00:01.239091\n",
            "episode: 257/2000, episode end value: 74354.50, duration: 0:00:00.851777\n",
            "episode: 258/2000, episode end value: 105742.52, duration: 0:00:00.549400\n",
            "episode: 259/2000, episode end value: 62509.62, duration: 0:00:01.049980\n",
            "episode: 260/2000, episode end value: 66371.68, duration: 0:00:00.322468\n",
            "episode: 261/2000, episode end value: 155877.64, duration: 0:00:00.130710\n",
            "episode: 262/2000, episode end value: 39163.76, duration: 0:00:00.283775\n",
            "episode: 263/2000, episode end value: 168543.00, duration: 0:00:00.161591\n",
            "episode: 264/2000, episode end value: 55474.05, duration: 0:00:00.283409\n",
            "episode: 265/2000, episode end value: 205867.19, duration: 0:00:00.806591\n",
            "episode: 266/2000, episode end value: 93989.84, duration: 0:00:01.868171\n",
            "episode: 267/2000, episode end value: 119529.29, duration: 0:00:03.623792\n",
            "episode: 268/2000, episode end value: 77004.25, duration: 0:00:00.274534\n",
            "episode: 269/2000, episode end value: 18282.81, duration: 0:00:00.414073\n",
            "episode: 270/2000, episode end value: 52638.22, duration: 0:00:03.132318\n",
            "episode: 271/2000, episode end value: 108581.13, duration: 0:00:01.088754\n",
            "episode: 272/2000, episode end value: 94247.41, duration: 0:00:00.249136\n",
            "episode: 273/2000, episode end value: 63453.57, duration: 0:00:00.221876\n",
            "episode: 274/2000, episode end value: 95027.34, duration: 0:00:00.715722\n",
            "episode: 275/2000, episode end value: 176435.94, duration: 0:00:00.144240\n",
            "episode: 276/2000, episode end value: 121293.48, duration: 0:00:00.803208\n",
            "episode: 277/2000, episode end value: 166226.91, duration: 0:00:00.171092\n",
            "episode: 278/2000, episode end value: 124958.70, duration: 0:00:00.207573\n",
            "episode: 279/2000, episode end value: 159192.52, duration: 0:00:01.514632\n",
            "episode: 280/2000, episode end value: 42617.12, duration: 0:00:00.554087\n",
            "episode: 281/2000, episode end value: 234866.07, duration: 0:00:00.478236\n",
            "episode: 282/2000, episode end value: 46442.72, duration: 0:00:00.661487\n",
            "episode: 283/2000, episode end value: 107694.99, duration: 0:00:00.391793\n",
            "episode: 284/2000, episode end value: 106646.94, duration: 0:00:00.235259\n",
            "episode: 285/2000, episode end value: 157516.07, duration: 0:00:00.152184\n",
            "episode: 286/2000, episode end value: 176414.05, duration: 0:00:00.846406\n",
            "episode: 287/2000, episode end value: 72317.89, duration: 0:00:00.133360\n",
            "episode: 288/2000, episode end value: 83545.06, duration: 0:00:00.128093\n",
            "episode: 289/2000, episode end value: 186820.05, duration: 0:00:00.337950\n",
            "episode: 290/2000, episode end value: 30473.08, duration: 0:00:01.317230\n",
            "episode: 291/2000, episode end value: 113120.64, duration: 0:00:00.273674\n",
            "episode: 292/2000, episode end value: 131255.77, duration: 0:00:03.847081\n",
            "episode: 293/2000, episode end value: 57510.69, duration: 0:00:04.250487\n",
            "episode: 294/2000, episode end value: 232365.96, duration: 0:00:07.321803\n",
            "episode: 295/2000, episode end value: 64728.39, duration: 0:00:00.398064\n",
            "episode: 296/2000, episode end value: 110362.69, duration: 0:00:09.289076\n",
            "episode: 297/2000, episode end value: 174438.60, duration: 0:00:01.676851\n",
            "episode: 298/2000, episode end value: 76089.45, duration: 0:00:00.418549\n",
            "episode: 299/2000, episode end value: 155075.74, duration: 0:00:00.477077\n",
            "episode: 300/2000, episode end value: 196205.60, duration: 0:00:00.252575\n",
            "episode: 301/2000, episode end value: 167666.32, duration: 0:00:00.448334\n",
            "episode: 302/2000, episode end value: 193233.87, duration: 0:00:05.191767\n",
            "episode: 303/2000, episode end value: 69942.43, duration: 0:00:09.281082\n",
            "episode: 304/2000, episode end value: 173939.44, duration: 0:00:04.257635\n",
            "episode: 305/2000, episode end value: 84735.43, duration: 0:00:00.085613\n",
            "episode: 306/2000, episode end value: 135891.92, duration: 0:00:01.400926\n",
            "episode: 307/2000, episode end value: 125406.45, duration: 0:00:00.059191\n",
            "episode: 308/2000, episode end value: 155091.61, duration: 0:00:00.058631\n",
            "episode: 309/2000, episode end value: 323694.00, duration: 0:00:03.650604\n",
            "episode: 310/2000, episode end value: 39303.06, duration: 0:00:08.929354\n",
            "episode: 311/2000, episode end value: 122383.63, duration: 0:00:01.408115\n",
            "episode: 312/2000, episode end value: 20131.61, duration: 0:00:00.127830\n",
            "episode: 313/2000, episode end value: 31574.12, duration: 0:00:01.927056\n",
            "episode: 314/2000, episode end value: 86189.40, duration: 0:00:02.143631\n",
            "episode: 315/2000, episode end value: 22803.32, duration: 0:00:00.773204\n",
            "episode: 316/2000, episode end value: 40213.21, duration: 0:00:04.637697\n",
            "episode: 317/2000, episode end value: 95585.45, duration: 0:00:02.695114\n",
            "episode: 318/2000, episode end value: 24883.79, duration: 0:00:01.188914\n",
            "episode: 319/2000, episode end value: 51426.47, duration: 0:00:00.098387\n",
            "episode: 320/2000, episode end value: 25975.61, duration: 0:00:00.572631\n",
            "episode: 321/2000, episode end value: 106835.22, duration: 0:00:03.216171\n",
            "episode: 322/2000, episode end value: 57170.75, duration: 0:00:00.280475\n",
            "episode: 323/2000, episode end value: 52413.39, duration: 0:00:00.139414\n",
            "episode: 324/2000, episode end value: 107542.08, duration: 0:00:02.638111\n",
            "episode: 325/2000, episode end value: 12093.23, duration: 0:00:00.098648\n",
            "episode: 326/2000, episode end value: 88010.59, duration: 0:00:00.600477\n",
            "episode: 327/2000, episode end value: 31269.98, duration: 0:00:00.093636\n",
            "episode: 328/2000, episode end value: 9498.02, duration: 0:00:00.090820\n",
            "episode: 329/2000, episode end value: 6170.07, duration: 0:00:00.085614\n",
            "episode: 330/2000, episode end value: 56769.98, duration: 0:00:05.635767\n",
            "episode: 331/2000, episode end value: 12588.25, duration: 0:00:00.085401\n",
            "episode: 332/2000, episode end value: 8466.39, duration: 0:00:00.083824\n",
            "episode: 333/2000, episode end value: 30579.07, duration: 0:00:00.116916\n",
            "episode: 334/2000, episode end value: 7010.11, duration: 0:00:00.100048\n",
            "episode: 335/2000, episode end value: 70736.50, duration: 0:00:01.301258\n",
            "episode: 336/2000, episode end value: 5644.43, duration: 0:00:00.082884\n",
            "episode: 337/2000, episode end value: 20809.30, duration: 0:00:01.136999\n",
            "episode: 338/2000, episode end value: 17018.10, duration: 0:00:00.074714\n",
            "episode: 339/2000, episode end value: 19091.67, duration: 0:00:00.557211\n",
            "episode: 340/2000, episode end value: 17864.83, duration: 0:00:00.062424\n",
            "episode: 341/2000, episode end value: 40805.75, duration: 0:00:01.541620\n",
            "episode: 342/2000, episode end value: 19138.09, duration: 0:00:00.183898\n",
            "episode: 343/2000, episode end value: 47829.99, duration: 0:00:02.898509\n",
            "episode: 344/2000, episode end value: 31944.62, duration: 0:00:04.185865\n",
            "episode: 345/2000, episode end value: 108888.91, duration: 0:00:03.436195\n",
            "episode: 346/2000, episode end value: 21971.10, duration: 0:00:00.597996\n",
            "episode: 347/2000, episode end value: 19234.82, duration: 0:00:02.186379\n",
            "episode: 348/2000, episode end value: 28738.51, duration: 0:00:00.646962\n",
            "episode: 349/2000, episode end value: 46179.91, duration: 0:00:03.388403\n",
            "episode: 350/2000, episode end value: 49757.93, duration: 0:00:01.481166\n",
            "episode: 351/2000, episode end value: 22164.89, duration: 0:00:00.880993\n",
            "episode: 352/2000, episode end value: 45546.51, duration: 0:00:02.151392\n",
            "episode: 353/2000, episode end value: 48255.88, duration: 0:00:01.547688\n",
            "episode: 354/2000, episode end value: 42592.59, duration: 0:00:02.901423\n",
            "episode: 355/2000, episode end value: 21300.13, duration: 0:00:00.837679\n",
            "episode: 356/2000, episode end value: 48672.82, duration: 0:00:01.536666\n",
            "episode: 357/2000, episode end value: 25969.85, duration: 0:00:01.893418\n",
            "episode: 358/2000, episode end value: 48595.48, duration: 0:00:02.354080\n",
            "episode: 359/2000, episode end value: 57278.40, duration: 0:00:01.214825\n",
            "episode: 360/2000, episode end value: 6519.09, duration: 0:00:00.667060\n",
            "episode: 361/2000, episode end value: 29858.48, duration: 0:00:02.154533\n",
            "episode: 362/2000, episode end value: 24759.06, duration: 0:00:00.919513\n",
            "episode: 363/2000, episode end value: 25135.99, duration: 0:00:01.150439\n",
            "episode: 364/2000, episode end value: 29098.06, duration: 0:00:01.543539\n",
            "episode: 365/2000, episode end value: 25874.74, duration: 0:00:00.627634\n",
            "episode: 366/2000, episode end value: 25644.81, duration: 0:00:00.720034\n",
            "episode: 367/2000, episode end value: 34909.24, duration: 0:00:02.762708\n",
            "episode: 368/2000, episode end value: 23987.67, duration: 0:00:00.319605\n",
            "episode: 369/2000, episode end value: 23608.56, duration: 0:00:00.936530\n",
            "episode: 370/2000, episode end value: 64380.64, duration: 0:00:00.970855\n",
            "episode: 371/2000, episode end value: 52096.45, duration: 0:00:01.854571\n",
            "episode: 372/2000, episode end value: 26053.83, duration: 0:00:00.749967\n",
            "episode: 373/2000, episode end value: 24660.87, duration: 0:00:00.879332\n",
            "episode: 374/2000, episode end value: 22559.77, duration: 0:00:01.292686\n",
            "episode: 375/2000, episode end value: 22288.34, duration: 0:00:00.750864\n",
            "episode: 376/2000, episode end value: 20271.22, duration: 0:00:00.580700\n",
            "episode: 377/2000, episode end value: 22111.71, duration: 0:00:00.622557\n",
            "episode: 378/2000, episode end value: 34278.01, duration: 0:00:01.826387\n",
            "episode: 379/2000, episode end value: 21075.34, duration: 0:00:00.741950\n",
            "episode: 380/2000, episode end value: 23178.66, duration: 0:00:01.532608\n",
            "episode: 381/2000, episode end value: 22814.23, duration: 0:00:00.801226\n",
            "episode: 382/2000, episode end value: 21486.13, duration: 0:00:00.710231\n",
            "episode: 383/2000, episode end value: 17013.02, duration: 0:00:01.743603\n",
            "episode: 384/2000, episode end value: 19017.50, duration: 0:00:00.600842\n",
            "episode: 385/2000, episode end value: 7325.40, duration: 0:00:00.637428\n",
            "episode: 386/2000, episode end value: 29319.05, duration: 0:00:03.352508\n",
            "episode: 387/2000, episode end value: 16473.73, duration: 0:00:00.380205\n",
            "episode: 388/2000, episode end value: 6346.51, duration: 0:00:00.665447\n",
            "episode: 389/2000, episode end value: 17572.65, duration: 0:00:00.610029\n",
            "episode: 390/2000, episode end value: 35176.78, duration: 0:00:02.824951\n",
            "episode: 391/2000, episode end value: 14523.25, duration: 0:00:00.257296\n",
            "episode: 392/2000, episode end value: 14796.32, duration: 0:00:00.280471\n",
            "episode: 393/2000, episode end value: 16532.90, duration: 0:00:01.245432\n",
            "episode: 394/2000, episode end value: 26613.02, duration: 0:00:02.410037\n",
            "episode: 395/2000, episode end value: 15722.84, duration: 0:00:00.780815\n",
            "episode: 396/2000, episode end value: 26939.82, duration: 0:00:01.577076\n",
            "episode: 397/2000, episode end value: 13679.59, duration: 0:00:00.676169\n",
            "episode: 398/2000, episode end value: 14068.31, duration: 0:00:00.595289\n",
            "episode: 399/2000, episode end value: 14625.48, duration: 0:00:01.127661\n",
            "episode: 400/2000, episode end value: 15164.46, duration: 0:00:01.218718\n",
            "episode: 401/2000, episode end value: 36794.67, duration: 0:00:02.032503\n",
            "episode: 402/2000, episode end value: 14675.55, duration: 0:00:01.104505\n",
            "episode: 403/2000, episode end value: 14452.43, duration: 0:00:00.500786\n",
            "episode: 404/2000, episode end value: 17821.33, duration: 0:00:00.888806\n",
            "episode: 405/2000, episode end value: 24923.82, duration: 0:00:02.291303\n",
            "episode: 406/2000, episode end value: 14859.01, duration: 0:00:00.732722\n",
            "episode: 407/2000, episode end value: 14512.61, duration: 0:00:00.145714\n",
            "episode: 408/2000, episode end value: 14265.15, duration: 0:00:00.491540\n",
            "episode: 409/2000, episode end value: 23790.86, duration: 0:00:02.205987\n",
            "episode: 410/2000, episode end value: 28735.21, duration: 0:00:02.220179\n",
            "episode: 411/2000, episode end value: 136397.08, duration: 0:00:02.788094\n",
            "episode: 412/2000, episode end value: 26061.08, duration: 0:00:00.357142\n",
            "episode: 413/2000, episode end value: 14633.25, duration: 0:00:00.611417\n",
            "episode: 414/2000, episode end value: 14152.35, duration: 0:00:00.702440\n",
            "episode: 415/2000, episode end value: 132371.27, duration: 0:00:01.076739\n",
            "episode: 416/2000, episode end value: 12885.11, duration: 0:00:00.230209\n",
            "episode: 417/2000, episode end value: 118855.19, duration: 0:00:00.562222\n",
            "episode: 418/2000, episode end value: 31651.01, duration: 0:00:00.886978\n",
            "episode: 419/2000, episode end value: 22309.33, duration: 0:00:00.711245\n",
            "episode: 420/2000, episode end value: 71578.40, duration: 0:00:01.087159\n",
            "episode: 421/2000, episode end value: 73549.66, duration: 0:00:01.716342\n",
            "episode: 422/2000, episode end value: 19641.95, duration: 0:00:00.654989\n",
            "episode: 423/2000, episode end value: 4473.05, duration: 0:00:00.375070\n",
            "episode: 424/2000, episode end value: 12380.53, duration: 0:00:00.254426\n",
            "episode: 425/2000, episode end value: 21328.27, duration: 0:00:01.464535\n",
            "episode: 426/2000, episode end value: 25472.33, duration: 0:00:02.009072\n",
            "episode: 427/2000, episode end value: 17808.95, duration: 0:00:00.737905\n",
            "episode: 428/2000, episode end value: 119471.98, duration: 0:00:01.544859\n",
            "episode: 429/2000, episode end value: 38148.91, duration: 0:00:01.131320\n",
            "episode: 430/2000, episode end value: 15644.53, duration: 0:00:00.519478\n",
            "episode: 431/2000, episode end value: 112480.29, duration: 0:00:00.559901\n",
            "episode: 432/2000, episode end value: 70013.43, duration: 0:00:00.831275\n",
            "episode: 433/2000, episode end value: 57627.07, duration: 0:00:00.546913\n",
            "episode: 434/2000, episode end value: 43614.32, duration: 0:00:02.224346\n",
            "episode: 435/2000, episode end value: 37931.27, duration: 0:00:01.433805\n",
            "episode: 436/2000, episode end value: 13286.87, duration: 0:00:00.373502\n",
            "episode: 437/2000, episode end value: 126144.30, duration: 0:00:00.276676\n",
            "episode: 438/2000, episode end value: 43921.07, duration: 0:00:00.748328\n",
            "episode: 439/2000, episode end value: 28976.16, duration: 0:00:00.687383\n",
            "episode: 440/2000, episode end value: 13624.19, duration: 0:00:00.340692\n",
            "episode: 441/2000, episode end value: 13725.48, duration: 0:00:00.967013\n",
            "episode: 442/2000, episode end value: 52704.79, duration: 0:00:00.575733\n",
            "episode: 443/2000, episode end value: 14316.80, duration: 0:00:00.543940\n",
            "episode: 444/2000, episode end value: 39163.58, duration: 0:00:01.164225\n",
            "episode: 445/2000, episode end value: 12856.91, duration: 0:00:00.742835\n",
            "episode: 446/2000, episode end value: 72958.93, duration: 0:00:01.827010\n",
            "episode: 447/2000, episode end value: 8278.43, duration: 0:00:00.075741\n",
            "episode: 448/2000, episode end value: 9416.19, duration: 0:00:00.088888\n",
            "episode: 449/2000, episode end value: 9056.20, duration: 0:00:00.083627\n",
            "episode: 450/2000, episode end value: 13677.05, duration: 0:00:00.142704\n",
            "episode: 451/2000, episode end value: 21853.34, duration: 0:00:00.415122\n",
            "episode: 452/2000, episode end value: 10634.42, duration: 0:00:00.098877\n",
            "episode: 453/2000, episode end value: 72810.68, duration: 0:00:03.647169\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # config\n",
        "    models_folder = \"linear_rl_trader_models\"\n",
        "    rewards_folder = \"linear_rl_trader_rewards\"\n",
        "    num_episodes = 2000\n",
        "    batch_size = 32  # unuseful here - batch size for sampling\n",
        "    initial_investment = 50000\n",
        "\n",
        "    mode = \"train\"\n",
        "\n",
        "    maybe_make_dir(models_folder)\n",
        "    maybe_make_dir(rewards_folder)\n",
        "\n",
        "    data = get_data()\n",
        "    n_timesteps, n_stocks = data.shape\n",
        "\n",
        "    n_train = n_timesteps // 2\n",
        "\n",
        "    train_data = data[:n_train]\n",
        "    test_data = data[n_train:]\n",
        "\n",
        "    env = MultiStockEnv(train_data, initial_investment)\n",
        "    state_size = env.state_dim\n",
        "    action_size = len(env.action_space)\n",
        "    agent = DQNAgent(state_size, action_size)\n",
        "    scaler = get_scaler(env)\n",
        "\n",
        "    # store the final value of the portfolio (end of episode)\n",
        "    portfolio_value = []\n",
        "\n",
        "    if mode == \"test\":\n",
        "        # then load the previous scaler\n",
        "        with open(f\"{models_folder}/scaler.pkl\", \"rb\") as f:\n",
        "            scaler = pickle.load(f)\n",
        "\n",
        "        # here for test we download the scaler -> we use the mean and std estimated on training set!\n",
        "\n",
        "        # remake the env with test data\n",
        "        env = MultiStockEnv(test_data, initial_investment)\n",
        "\n",
        "        # make sure epsilon is not 1!\n",
        "        # no need to run multiple episodes if epsilon = 0, it's deterministic\n",
        "        agent.epsilon = 0.01\n",
        "\n",
        "        # load trained weights\n",
        "        agent.load(f\"{models_folder}/linear.npz\")\n",
        "\n",
        "    # play the game num_episodes times\n",
        "    for e in range(num_episodes):\n",
        "        t0 = datetime.now()  # the time to measure the duration of each episode\n",
        "        val = play_one_episode(agent, env, mode)\n",
        "        dt = datetime.now() - t0\n",
        "        print(\n",
        "            f\"episode: {e + 1}/{num_episodes}, episode end value: {val:.2f}, duration: {dt}\"\n",
        "        )  # we print times for each episode\n",
        "        portfolio_value.append(val)  # append episode end portfolio value\n",
        "\n",
        "    # save the weights when we are done\n",
        "    if mode == \"train\":\n",
        "        # save the DQN\n",
        "        agent.save(f\"{models_folder}/linear.npz\")\n",
        "\n",
        "        # save the scaler\n",
        "        with open(f\"{models_folder}/scaler.pkl\", \"wb\") as f:\n",
        "            pickle.dump(scaler, f)\n",
        "\n",
        "        # plot losses\n",
        "        plt.plot(agent.model.losses)\n",
        "        plt.show()\n",
        "\n",
        "    # save portfolio value for each episode\n",
        "    np.save(f\"{rewards_folder}/{mode}.npy\", portfolio_value)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "9ad53c5c79255b00e070729227298519a06299ed18c566c96066e12e994c9836"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
